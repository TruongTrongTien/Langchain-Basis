{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LEARN\\LangChain Basis\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\LEARN\\LangChain Basis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LEARN\\LangChain Basis\\.venv\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tools\n",
    "def get_current_time(*args, **kwargs):\n",
    "    \"\"\"Returns the current time in H:MM AM/PM format.\"\"\"\n",
    "    import datetime\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%I:%M %p\")\n",
    "\n",
    "\n",
    "def search_wikipedia(query):\n",
    "    \"\"\"Searches Wikipedia and returns the summary of the first result.\"\"\"\n",
    "    from wikipedia import summary\n",
    "\n",
    "    try:\n",
    "        # Limit to two sentences for brevity\n",
    "        return summary(query, sentences=2)\n",
    "    except:\n",
    "        return \"I couldn't find any information on that.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools that the agent can use\n",
    "get_current_time_tool = Tool(\n",
    "    name=\"Time\",\n",
    "    func=get_current_time,\n",
    "    description=\"Useful for when you need to know the current time.\",\n",
    ")\n",
    "\n",
    "search_wikipedia_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=search_wikipedia,\n",
    "    description=\"Useful for when you need to know information about a topic.\",\n",
    ")\n",
    "\n",
    "tools = [get_current_time_tool, search_wikipedia_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LEARN\\LangChain Basis\\.venv\\lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "# Load the correct JSON Chat Prompt from the hub\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a structured Chat Agent with Conversation Buffer Memory\n",
    "# ConversationBufferMemory stores the conversation history, allowing the agent to maintain context across interactions\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial system message to set the context for the chat\n",
    "# SystemMessage is used to define a message from the system to the agent, setting initial instructions or context\n",
    "# initial_message = \"You are an AI assistant that can provide helpful answers using available tools.\\nIf you are unable to answer, you can use the following tools: Time and Wikipedia.\"\n",
    "# memory.chat_memory.add_message(SystemMessage(content=initial_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_structured_chat_agent initializes a chat agent designed to interact using a structured prompt and tools\n",
    "# It combines the language model (llm), tools, and prompt to create an interactive agent\n",
    "agent = create_structured_chat_agent(\n",
    "    llm=llm, \n",
    "    tools=tools, \n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentExecutor is responsible for managing the interaction between the user input, the agent, and the tools\n",
    "# It also handles memory to ensure context is maintained throughout the conversation\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory,  # Use the conversation memory to maintain context\n",
    "    handle_parsing_errors=True,  # Handle any parsing errors gracefully\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "[SystemMessage(content='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nTime(*args, **kwargs) - Useful for when you need to know the current time., args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nWikipedia(query) - Useful for when you need to know information about a topic., args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Time, Wikipedia\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), HumanMessage(content='how old was George Washington when he died?'), HumanMessage(content='how old was George Washington when he died?\\n\\n\\n (reminder to respond in a JSON blob no matter what)')]\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out when George Washington died and when he was born to calculate his age.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"George Washington\"\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3mGeorge Washington (February 22, 1732 – December 14, 1799) was an American Founding Father, military officer, and politician who served as the first president of the United States from 1789 to 1797. Appointed by the Second Continental Congress as commander of the Continental Army in 1775, Washington led Patriot forces to victory in the American Revolutionary War and then served as president of the Constitutional Convention in 1787, which drafted the current Constitution of the United States.\u001b[0m[SystemMessage(content='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nTime(*args, **kwargs) - Useful for when you need to know the current time., args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nWikipedia(query) - Useful for when you need to know information about a topic., args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Time, Wikipedia\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), HumanMessage(content='how old was George Washington when he died?'), HumanMessage(content='how old was George Washington when he died?\\n\\nThought: I need to find out when George Washington died and when he was born to calculate his age.\\nAction:\\n```json\\n{\\n  \"action\": \"Wikipedia\",\\n  \"action_input\": \"George Washington\"\\n}\\n```\\nObservation: George Washington (February 22, 1732 – December 14, 1799) was an American Founding Father, military officer, and politician who served as the first president of the United States from 1789 to 1797. Appointed by the Second Continental Congress as commander of the Continental Army in 1775, Washington led Patriot forces to victory in the American Revolutionary War and then served as president of the Constitutional Convention in 1787, which drafted the current Constitution of the United States.\\nThought: \\n (reminder to respond in a JSON blob no matter what)')]\n",
      "\u001b[32;1m\u001b[1;3mThought: I have the dates of his birth and death, now I need to calculate the difference.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"George Washington died at the age of 67.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: George Washington died at the age of 67.\n"
     ]
    }
   ],
   "source": [
    "# Chat Loop to interact with the user\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        break\n",
    "\n",
    "    # Add the user's message to the conversation memory\n",
    "    memory.chat_memory.add_message(HumanMessage(content=user_input))\n",
    "\n",
    "    # Invoke the agent with the user input and the current chat history\n",
    "    response = agent_executor.invoke({\"input\": user_input})\n",
    "    print(\"Bot:\", response[\"output\"])\n",
    "\n",
    "    # Add the agent's response to the conversation memory\n",
    "    memory.chat_memory.add_message(AIMessage(content=response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an AI assistant that can provide helpful answers using available tools.\\nIf you are unable to answer, you can use the following tools: Time and Wikipedia.'),\n",
       " HumanMessage(content='hi'),\n",
       " SystemMessage(content='Goodbye!')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
